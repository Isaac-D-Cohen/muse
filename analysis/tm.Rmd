---
title: "Text mining using the tm package"
date: "`r Sys.Date()`"
output:
  workflowr::wflow_html:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The [tm](https://cran.r-project.org/web/packages/tm/index.html) package is a framework for text mining applications within R.

```{r load_package}
library(tm)
packageVersion("tm")
```

## Getting started

The `crude` corpus:

>This data set holds 20 news articles with additional meta information from the Reuters-21578 data set. All documents belong to the topic crude dealing with crude oil.

```{r crude}
data(crude)
class(crude)
```

`inspect` can be used to display detailed information on a corpus, a term-document matrix, or a text document.

```{r inspect_crude}
inspect(crude[1:3])
```

Create a Term Document Matrix.

```{r term_document_matrix}
tdm <- TermDocumentMatrix(crude)
tdm
```

Convert to matrix.

```{r term_document_matrix_to_matrix}
crude_matrix <- as.matrix(tdm)
dim(crude_matrix)
```

Check out the matrix. We need to remove the symbols!

```{r check_out_matrix}
crude_matrix[1:6, 1:6]
```

Sparsity is the number of zeros, i.e., words that are not present in documents.

```{r calc_sparsity}
prop.table(table(crude_matrix == 0))
```

Functions that can be used on a `TermDocumentMatrix`.

```{r methods_term_document_matrix}
methods(class = "TermDocumentMatrix")
```

Clean corpus.

```{r clean_corpus}
clean_corpus <- function(x){
  x |>
    tm_map(removePunctuation) |>
    tm_map(stripWhitespace) |>
    tm_map(content_transformer(function(x) iconv(x, to='UTF-8', sub='byte'))) |>
    tm_map(removeNumbers) |>
    tm_map(removeWords, stopwords("en")) |>
    tm_map(content_transformer(tolower)) |>
    tm_map(removeWords, c("etc","ie", "eg", stopwords("english")))
}

tdm <- TermDocumentMatrix(clean_corpus(crude))

crude_matrix <- as.matrix(tdm)
crude_matrix[1:6, 1:6]
```

`findFreqTerms` finds frequent terms in a document-term or term-document matrix.

```{r find_freq_terms}
findFreqTerms(x = tdm, lowfreq = 10)
```

Limit matrix to specific words.

```{r limit_matrix}
inspect(
  x = DocumentTermMatrix(
    x = crude,
    list(dictionary = c("government", "market", "official")
    )
  )
)
```

`findAssocs` finds associations in a document-term or term-document matrix.

```{r find_assocs}
findAssocs(x = tdm, terms = 'government', corlimit = 0.8)
```

Simple analysis on the matrix.

Most common words.

```{r most_common_words}
head(sort(rowSums(crude_matrix), decreasing = TRUE))
```

Correlation.

```{r correlation}
cor(crude_matrix[,1], crude_matrix[,2])
```

Clustering.

```{r clustering}
set.seed(31)
my_cluster <- kmeans(x = t(crude_matrix), centers = 4)
my_cluster$cluster
```

Check headings of cluster 3.

```{r check_clustering}
meta(crude, 'heading')[my_cluster$cluster == 3]
```

## Vignette

Following the [vignette](https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf).

The main structure for managing documents in the `tm` package is a `Corpus`, which represents a collection of text documents. A corpus is an abstract concept and there can exist several implementations in parallel. The default implementation is the `VCorpus`, which is short for Volatile Corpus. The `PCorpus` implements a Permanent Corpus and the documents are physically stored outside of R.

Within the corpus constructor, x must be a Source object which abstracts the input location. `tm` provides a set of predefined sources, e.g., `DirSource`, `VectorSource`, or `DataframeSource`, which handle a directory, a vector interpreting each component as document, or data frame like structures (like CSV files), respectively. 

Below is an example of reading in a plain text file in the directory `txt` containing Latin (lat) texts by the Roman poet Ovid.

```{r prepare_ovid}
txt <- system.file("texts", "txt", package = "tm")
(ovid <- VCorpus(DirSource(txt, encoding = "UTF-8"), readerControl = list(language = "lat")))
```

For simple examples `VectorSource` is quite useful, as it can create a corpus from character vectors.

```{r vector_source}
docs <- c("This is a text.", "This another one.")
VCorpus(VectorSource(docs))
```

The `tm` package ships with several readers (e.g., `readPlain()`, `readPDF()`, and `readDOC()`). See `?getReaders()` for an up-to-date list of available readers. 

Create a data frame for creating a corpus.

```{r my_df}
my_df <- data.frame(
  doc_id = c("doc 1" , "doc 2" , "doc 3" ),
  text = c("this is a sentence", "this is another sentence", "who what how"),
  title = c("title 1" , "title 2" , "title 3" ),
  authors = c("author 1" , "author 2" , "author 3" ),
  topics = c("topic 1" , "topic 2" , "topic 3" ),
  stringsAsFactors = FALSE
)

my_df
```

A data frame source interprets each row of the data frame as a document. The first column must be named `doc_id` and contain a unique string identifier for each document. The second column must be named `text` and contain a UTF-8 encoded string representing the document's content. Optional additional columns are used as document level metadata.

```{r corpus_from_df}
(my_corpus <- Corpus(DataframeSource(my_df)))
```

Create a `TermDocumentMatrix`.

```{r my_corpus_to_tdm}
my_tdm <- TermDocumentMatrix(my_corpus)
my_tdm
```

Check out the matrix.

```{r my_tdm_to_matrix}
as.matrix(my_tdm)
```

### Transformations

Once we have a corpus we typically want to modify the documents in it, e.g., stemming, stop word removal, etc. In `tm`, all this functionality is performed via the `tm_map()` function which applies (maps) a function to all elements of the corpus; this is called a transformation. All transformations work on single text documents and `tm_map()` just applies them to all documents in a corpus.

```{r reuters}
reut21578 <- system.file("texts", "crude", package = "tm")
reuters <- VCorpus(DirSource(reut21578, mode = "binary"), readerControl = list(reader = readReut21578XMLasPlain))
reuters
```

Remove whitespace.

```{r strip_whitespace}
reuters <- tm_map(reuters, stripWhitespace)
```

We can use arbitrary character processing functions as transformations as long as the function returns a text document. In this case we use `content_transformer()` which provides a convenience wrapper to access and set the content of a document. Consequently most text manipulation functions from base R can directly be used with this wrapper. This works for `tolower()` as used here but also with `gsub()` which comes quite handy for a broad range of text manipulation tasks.

```{r tolower}
reuters <- tm_map(reuters, content_transformer(tolower))
```

Remove stopwords.

```{r stopwords}
reuters <- tm_map(reuters, removeWords, stopwords("english"))
```

From <https://www.geeksforgeeks.org/introduction-to-stemming/>:

>Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words "chocolates", "chocolatey", "choco" to the root word, "chocolate" and "retrieval", "retrieved", "retrieves" reduce to the stem "retrieve". Stemming is an important part of the pipelining process in Natural language processing. The input to the stemmer is tokenized words. How do we get these tokenized words? Well, tokenization involves breaking down the document into different words.

This requires the `SnowballC` package.

```{r stem_document}
library(SnowballC)
tm_map(reuters, stemDocument)
```

Often it is of special interest to filter out documents satisfying given properties. For this purpose the function `tm_filter` is designed. It is possible to write custom filter functions which get applied to each document in the corpus. Alternatively, we can create indices based on selections and subset the corpus with them. E.g., the following statement filters out those documents having an ID equal to "237" and the string "INDONESIA SEEN AT CROSSROADS OVER ECONOMIC CHANGE" as their heading.

```{r filtering}
idx <- meta(reuters, "id") == '237' & meta(reuters, "heading") == 'INDONESIA SEEN AT CROSSROADS OVER ECONOMIC CHANGE'
reuters[idx]
```

### Term-Document Matrices

A common approach in text mining is to create a term-document matrix from a corpus. In the `tm` package the classes `TermDocumentMatrix` and `DocumentTermMatrix` (depending on whether you want terms as rows and documents as columns, or vice versa) employ sparse matrices for corpora. Inspecting a term-document matrix displays a sample, whereas `as.matrix()` yields the full matrix in dense format (which can be very memory consuming for large matrices).

```{r inspect_dtm}
dtm <- DocumentTermMatrix(reuters)
inspect(dtm)
```

Find terms that occur at least five times using the `findFreqTerms()` function.

```{r find_freq_terms_dtm}
findFreqTerms(dtm, 5)
```

Find associations (i.e., terms which correlate) with at least 0.8 correlation for the term "opec" using the `findAssocs()` function.

```{r find_assocs_opec}
findAssocs(dtm, "opec", 0.8)
```

Term-document matrices tend to get very big already for normal sized data sets. Therefore we provide a method to remove sparse terms, i.e., terms occurring only in very few documents. Normally, this reduces the matrix dramatically without losing significant relations inherent to the matrix:

```{r remove_sparse_terms}
inspect(removeSparseTerms(dtm, 0.4))
```

A dictionary is a (multi-)set of strings. It is often used to denote relevant terms in text mining. We represent a dictionary with a character vector which may be passed to the `DocumentTermMatrix()` constructor as a control argument. Then the created matrix is tabulated against the dictionary, i.e., only terms from the dictionary appear in the matrix. This allows to restrict the dimension of the matrix _a priori_ and to focus on specific terms for distinct text mining contexts.

```{r dictionary}
inspect(DocumentTermMatrix(reuters, list(dictionary = c("prices", "crude", "oil"))))
```
